#' Projection onto a Variety
#'
#' An R-based implementation of gradient-descent homotopies with adaptive step
#' sizes for Euler prediction. The Lagrange version uses Newton's method on the
#' Lagrangian system.
#'
#'
#' @param x0 A numeric vector giving one point to be projected, or a numeric
#'   matrix/data frame whose rows are points to be projected.
#' @param poly An `mpoly` object, typically created with [mpoly::mp()].
#' @param dt The t-mesh size for the homotopy.
#' @param varorder A character vector specifying the variable order to pass to
#'   [mpoly::as.function.mpoly()].
#' @param n_correct The number of Newton correction iterations to use.
#' @param al A numeric vector of length 2; the patch to do projective
#'   calculations over.
#' @param tol A tolerance on the residual; a warning is issued if the magnitude
#'   of the residual is larger than `tol`.
#' @param tol_x A tolerance on subsequent step sizes.
#' @param method Used in [project_onto_variety_lagrange()],
#'   [project_onto_variety_gradient_descent()], and
#'   [project_onto_variety_newton()]. In the Lagrange method, if
#'   `"newton"`, a simple R implementation of Newton's method to solve the
#'   nonlinear algebraic system generated by the Lagrangian; otherwise, a
#'   character string to pass to [stats::optim()] to minimize
#'   the sum of the squares of the Lagrangian. In the gradient-descent and
#'   Newton methods, `method` controls the line-search/fixed-step update:
#'   `"line"` (line search), `"optimal"`, or `"fixed"`.
#' @param maxit Number of maximum iterations in solving Newton's method.
#' @param ga Learning rate for gradient descent.
#' @param max_ga Maximum learning rate for gradient descent line search.
#' @param message If `TRUE`, the user is issued messages on the algorithm's
#'   progress.
#' @param ... Additional arguments to pass to [stats::optim()] when `method` is
#'   not `"newton"`.
#' @param gfunc,dgfunc,ddgfunc The polynomial [poly], its gradient, and its
#'   Hessian as functions. Only used in [project_onto_variety()], and computed
#'   internally if not provided.
#' @param bias A multiple to add to the identity to make the Jacobian
#'   invertible.
#' @param adaptive Defaults to `TRUE`. Whether to use adaptive step sizes.
#' @param dt_min,dt_max Minimum and maximum allowed step sizes during adaptive
#'   integration (default: `1e-6` and `0.1`).
#' @param error_tol Tolerance used for adaptive step size control
#'   (default: `0.01`). Smaller values give more accurate results at the cost of
#'   runtime.
#' @return If `x0` is a vector, a numeric vector the same length as `x0`. If
#'   `x0` is a matrix/data frame, a matrix/data frame of projected points with
#'   the same number of rows.
#' @references Griffin, Z. and J. Hauenstein (2015). Real solutions to systems
#'   of polynomial equations and parameter continuation. \emph{Advances in
#'   Geometry} 15(2), pp.173--187.
#' @references Bates, D., J. Hauenstein, A. Sommese, and C. Wampler (2013).
#'   Numerically Solving Polynomial Systems with Bertini. SIAM. pp.34--35.
#' @author David Kahle
#' @name project-onto-variety
#' @examples
#'
#' library("ggplot2")
#' library("mpoly")
#'
#' \dontrun{
#' ## basic usage
#' x0 <- c(1, 1)
#' p1 <- mp("x^2 + y^2 - 1")
#' x1_proj <- project_onto_variety(x0, p1)
#' x1_proj
#'
#' # Residual on the variety should be near zero
#' as.function(p1)(x1_proj)
#'
#' df1 <- data.frame(
#'   x = x0[1], y = x0[2],
#'   x_proj = x1_proj[1], y_proj = x1_proj[2]
#' )
#' ggplot() +
#'   geom_variety(poly = p1, xlim = c(-2, 2), ylim = c(-2, 2)) +
#'   geom_segment(aes(x, y, xend = x_proj, yend = y_proj), data = df1) +
#'   coord_equal()
#'
#' ## adaptive time stepping (default) versus fixed step size
#' x2_adapt <- project_onto_variety(x0, p1)
#' x2_fixed <- project_onto_variety(x0, p1, adaptive = FALSE, dt = 0.01)
#' x2_strict <- project_onto_variety(x0, p1, error_tol = 0.001)
#'
#' rbind(
#'   adaptive = x2_adapt,
#'   fixed = x2_fixed,
#'   adaptive_strict = x2_strict
#' )
#'
#' # Optional: inspect adaptive step messages
#' project_onto_variety(x0, p1, message = TRUE)
#'
#' ## precomputing polynomial/gradient/Hessian functions
#' varorder <- c("x", "y")
#' gfunc <- as.function(p1, varorder = varorder)
#' dg <- stats::deriv(p1, var = varorder)
#' dgfunc <- as.function(dg, varorder = varorder)
#' ddg <- lapply(dg, stats::deriv, var = varorder)
#' ddgfunc_list <- lapply(ddg, as.function, varorder = varorder, silent = TRUE)
#' ddgfunc <- function(x) sapply(ddgfunc_list, function(f) f(x))
#' project_onto_variety(x0, p1, gfunc = gfunc, dgfunc = dgfunc, ddgfunc = ddgfunc)
#'
#' ## projecting multiple points (matrix or data frame input)
#' x2 <- rbind(c(1, 1), c(-1, 0.3), c(0.2, -1.3))
#' project_onto_variety(x2, p1)
#' project_onto_variety(as.data.frame(x2), p1)
#'
#' ## alternative projection methods
#' project_onto_variety_lagrange(x0, p1)
#' project_onto_variety_newton(x0, p1)
#' project_onto_variety_gradient_descent(x0, p1, method = "line")
#' project_onto_variety_gradient_descent(x0, p1, method = "optimal")
#' project_onto_variety_gradient_descent(x0, p1, method = "fixed")
#'
#' ## naive usages / method comparison on a small grid
#' # (gradient descent methods minimize g(x)^2 directly)
#' library("dplyr")
#' set.seed(1)
#' grid <- expand.grid(x = seq(-1, 1, by = 0.5), y = seq(-1, 1, by = 0.5))
#' grid$x <- jitter(grid$x)
#' grid$y <- jitter(grid$y)
#'
#' proj_homotopy <- project_onto_variety(grid, p1)
#' proj_gd_opt <- project_onto_variety_gradient_descent(grid, p1, method = "optimal")
#' proj_newton <- project_onto_variety_newton(grid, p1)
#'
#' names(proj_homotopy) <- c("x_proj", "y_proj")
#' names(proj_gd_opt) <- c("x_proj", "y_proj")
#' names(proj_newton) <- c("x_proj", "y_proj")
#'
#' df_cmp <- bind_rows(
#'   bind_cols(grid, proj_homotopy) |> mutate(method = "homotopy (adaptive default)"),
#'   bind_cols(grid, proj_gd_opt)   |> mutate(method = "naive gd on g^2 (optimal)"),
#'   bind_cols(grid, proj_newton)   |> mutate(method = "newton on g^2")
#' )
#'
#' ggplot() +
#'   geom_variety(poly = p1, xlim = c(-1.2, 1.2), ylim = c(-1.2, 1.2)) +
#'   geom_segment(
#'     aes(x, y, xend = x_proj, yend = y_proj),
#'     data = df_cmp, inherit.aes = FALSE, alpha = 0.6
#'   ) +
#'   geom_point(aes(x, y), data = grid, inherit.aes = FALSE, size = 0.8) +
#'   coord_equal() +
#'   facet_wrap(~ method)
#'
#' ## changing adaptive control parameters
#' project_onto_variety(
#'   x0, p1,
#'   adaptive = TRUE,
#'   dt = 0.05,
#'   dt_min = 1e-5,
#'   dt_max = 0.2,
#'   error_tol = 0.005,
#'   message = TRUE
#' )
#'
#' ## more complex curve
#' p_complex <- mp("(x^2 + y^2)^2 - 2 * (x^2 - y^2)")
#' x_complex <- c(1, 1)
#' x_complex_proj <- project_onto_variety(x_complex, p_complex)
#' df_complex <- data.frame(
#'   x = x_complex[1], y = x_complex[2],
#'   x_proj = x_complex_proj[1], y_proj = x_complex_proj[2]
#' )
#' ggplot() +
#'   geom_variety(poly = p_complex, xlim = c(-2, 2), ylim = c(-2, 2)) +
#'   geom_segment(aes(x, y, xend = x_proj, yend = y_proj), data = df_complex) +
#'   coord_equal()
#'
#' ## projecting a sample from rvnorm (batch usage)
#' # cut down on draws for example runtime
#' samps <- rvnorm(500, p1, sd = 0.05, output = "tibble")
#' idx <- sample(seq_len(nrow(samps)), size = min(75, nrow(samps)))
#' subsamps <- samps[idx, , drop = FALSE]
#' proj_sub <- project_onto_variety(subsamps[, c("x", "y")], p1)
#' names(proj_sub) <- c("x_proj", "y_proj")
#' df_sub <- dplyr::bind_cols(subsamps, proj_sub)
#'
#' ggplot(df_sub, aes(x, y)) +
#'   geom_segment(aes(xend = x_proj, yend = y_proj), alpha = 0.4) +
#'   geom_point(size = 0.8) +
#'   geom_variety(poly = p1, xlim = c(-2, 2), ylim = c(-2, 2), inherit.aes = FALSE) +
#'   coord_equal()
#'
#' ## higher-dimensional example
#' x3 <- c(1, 1, 1)
#' p2 <- mp("x^2 + y^2 + z^2 - 1")
#' project_onto_variety(x3, p2)
#' }




#' @rdname project-onto-variety
#' @export
project_onto_variety <- function(
    x0, poly, dt = .01, varorder = sort(mpoly::vars(poly)),
    n_correct = 2, al = rnorm(2),
    message = FALSE, tol = .Machine$double.eps^(1/2),
    gfunc, dgfunc, ddgfunc, bias = 0,
    adaptive = TRUE,
    dt_min = 1e-6, dt_max = 0.1, error_tol = .01
) {
  # Homotopy from t=1 (x0 offset equation) to t=0 (target variety equation).
  t_start <- 1
  t_end <- 0
  if (missing(x0)) stop("`x0` must be supplied.")
  if (missing(poly)) stop("`poly` must be supplied.")
  if (!is.numeric(al) || length(al) < 2 || any(!is.finite(al[1:2]))) {
    stop("`al` must be a numeric vector with at least two finite entries.")
  }


  # Build polynomial, Jacobian, and Hessian function handles when not supplied.
  if (missing(gfunc) || missing(dgfunc) || missing(ddgfunc)) {

    if (!missing(gfunc) || !missing(dgfunc) || !missing(ddgfunc)) {
      # If one derivative helper is missing, rebuild all three consistently.
      warning(
        "If any of `gfunc`, `dgfunc`, or `ddgfunc` is not provided,",
        " they are all computed internally.",
        call. = FALSE
      )
    }

    # polynomial as a function
    g <- poly
    gfunc <- as.function(g, varorder = varorder, silent = TRUE)

    # jacobian
    dg <- deriv(g, var = varorder)
    dgfunc <- as.function(dg, varorder = varorder, silent = TRUE)

    # hessian
    ddg <- lapply(dg, deriv, var = varorder)
    ddgfunc_list <- lapply(ddg, as.function, varorder = varorder, silent = TRUE)
    ddgfunc <- function(x) sapply(ddgfunc_list, function(f) f(x))

  }


  # Vectorized convenience path for row-wise projection of matrices/data frames.
  if (is.matrix(x0) || is.data.frame(x0)) {
    out <- apply(
      x0, 1, project_onto_variety,
      poly = poly, dt = dt, varorder = varorder, n_correct = n_correct,
      al = al, message = message, tol = tol,
      gfunc = gfunc, dgfunc = dgfunc, ddgfunc = ddgfunc,
      bias = bias, adaptive = adaptive,
      dt_min = dt_min, dt_max = dt_max, error_tol = error_tol
    )
    out <- t(out)
    if (is.data.frame(x0)) out <- as.data.frame(out)
    if (inherits(x0, "tbl_df")) class(out) <- c("tbl_df", "tbl", "data.frame")
    return(out)
  }

  # Main computation for one starting point x0.
  n_vars <- length(varorder)

  ts <- seq(1, 0, -dt)
  vn <- c(x0, al[1], 0)

  Ha <- function(v, t) {
    # Augmented homotopy system in (x, lambda0, lambda1).
    x <- v[1:n_vars]; la <- v[-(1:n_vars)]
    c(
      gfunc(x) - t*gfunc(x0),
      as.numeric(cbind((x-x0), dgfunc(x)) %*% la),
      la[1] + la[2]*al[2] - al[1]
    )
  }
  # Ha(vn, .99)

  JHa <- function(v, t) {
    x <- v[1:n_vars]
    la0 <- v[n_vars+1]
    la1 <- v[n_vars+2]
    al1 <- al[2]
    rbind(
      c(dgfunc(x), 0, 0),
      cbind(
        la0*diag(n_vars) + la1*ddgfunc(x),
        x - x0,
        dgfunc(x)
      ),
      c(rep(0, n_vars), 1, al1)
    )
  }
  # JHa(vn, .99)

  # partial derivative of H w.r.t t:
  Ht <- function(v, t) c(-gfunc(x0), rep(0, n_vars + 2 - 1))
  # Ht(c(1,1), 1)

  if (adaptive) {
    # Adaptive predictor-corrector (Euler + Heun) with error control.
    t <- t_start
    while (t > t_end) {
      h <- min(dt, t - t_end)

      # Predictor: Euler step
      F1 <- solve(JHa(vn, t), Ht(vn, t))
      v_euler <- vn + h * F1

      # Corrector: Heun step
      F2 <- solve(JHa(v_euler, t - h), Ht(v_euler, t - h))
      v_heun <- vn + 0.5 * h * (F1 + F2)

      err <- sqrt(sum((v_heun - v_euler)^2))

      if (err < error_tol) {
        # Accept step and perform Newton corrections on the new time slice.
        vn <- v_euler
        t <- t - h

        for (. in 1:n_correct) {
          vn <- vn - solve(JHa(vn, t) + bias * diag(n_vars + 2), Ha(vn, t))
        }

        if (message) message("t: ", round(t, 5), " | dt: ", round(h, 5))

        dt <- min(dt_max, h * min(2, (error_tol / err)^0.5))
      } else {
        # Reject step and shrink dt.
        dt <- max(dt_min, h * max(0.1, (error_tol / err)^0.5))
        if (message) message("  Rejected step. Reducing dt to ", round(dt, 6))
      }
    }

  } else {
    # Fixed-step predictor + Newton-corrector path.
    ts <- seq(t_start, t_end, -dt)
    for (i in 2:length(ts)) {
      vn <- vn + solve(JHa(vn, t = ts[i - 1]), Ht(vn, t = ts[i - 1])) * dt
      if (message) message(paste(round(vn, 5), collapse = " "))

      for (. in 1:n_correct) {
        vn <- vn - solve(
          JHa(vn, t = ts[i]) + bias * diag(n_vars + 2),
          Ha(vn, t = ts[i])
        )
        if (message) message("  ", paste(round(vn, 5), collapse = " "))
      }
    }
  }

  resid <- gfunc(vn[1:n_vars])
  if (abs(resid) >= tol) {
    warning(
      sprintf("Tolerance not met (residual = %f).", resid),
      call. = FALSE
    )
  }
  vn[1:n_vars]
}




#' @rdname project-onto-variety
#' @export
project_onto_variety_lagrange <- function(
    x0, poly, varorder = mpoly::vars(poly), method = "newton", maxit = 1e3,
    tol = .Machine$double.eps^(1/2), tol_x = .Machine$double.eps^(1/2),
    message = FALSE, ...
  ) {
  # Solve KKT stationarity system for closest-point projection.

  # Vectorized convenience path for row-wise projection.
  if (is.matrix(x0) || is.data.frame(x0)) {
    out <- apply(
      x0, 1, project_onto_variety_lagrange,
      poly = poly, varorder = varorder, method = method, maxit = maxit,
      tol = tol, tol_x = tol_x,
      message = message, ...
    )
    out <- t(out)
    if (is.data.frame(x0)) out <- as.data.frame(out)
    if (inherits(x0, "tbl_df")) class(out) <- c("tbl_df", "tbl", "data.frame")
    return(out)
  }

  # Build Lagrangian and stationarity equations.
  form <- paste0("(", varorder, " - ", x0, ")^2", collapse = " + ")
  L <- mp(form) + mp("la")*poly
  dL <- stats::deriv(L, var = c(varorder, "la"))
  dLf <- as.function(dL, varorder = c(varorder, "la"), silent = TRUE)

  if (method == "newton") {

    ddL <- lapply(dL, stats::deriv, var = c(varorder, "la"))
    ddLf <- lapply(
      ddL,
      as.function,
      varorder = c(varorder, "la"),
      silent = TRUE
    )
    H <- function(v) do.call(rbind, lapply(ddLf, function(f) f(v)))

    la0 <- stats::optimize(
      function(.) sum(dLf(c(x0, .))^2),
      lower = 0,
      upper = 1e3
    )$minimum

    xn_1 <- c(x0, la0)
    xn <- xn_1 + solve( H(xn_1), -dLf(xn_1) )

    count <- 0L
    while (
      sum(abs(dLf(xn))) > tol &&
      sum(abs(xn - xn_1)) > tol_x &&
      count <= maxit
    ) {
      xn_1 <- xn
      xn <- xn_1 + solve( H(xn_1), -dLf(xn_1) )
      if (message) message(paste(round(xn, 5), collapse = " "))
      count <- count + 1L
    }
    xn <- xn[seq_along(varorder)]

  } else {

    la0 <- optimize(
      function(.) sum(dLf(c(x0, .))^2),
      lower = 0,
      upper = 1e3
    )$minimum
    xn <- stats::optim(
      c(x0, la0),
      function(.) sum(dLf(.))^2,
      method = method,
      ...
    )$par[1:2]
    xn <- xn[seq_along(varorder)]

  }

  pf  <- as.function(poly, varorder = varorder, silent = TRUE)
  resid <- pf(xn)
  if (abs(resid) >= tol) {
    warning(
      sprintf("Tolerance not met (residual = %f).", resid),
      call. = FALSE
    )
  }

  xn

}







#' @rdname project-onto-variety
#' @export
project_onto_variety_gradient_descent <- function(
    x0, poly, varorder = mpoly::vars(poly), ga = .01, max_ga = .1,
    method = c("line", "optimal", "fixed"),
    tol = .Machine$double.eps^(1/2), tol_x = .Machine$double.eps^(1/2),
    maxit = 1e3, message = FALSE
) {
  # Minimize g(x)^2 using gradient descent variants.

  # Vectorized convenience path for row-wise projection.
  if (is.matrix(x0) || is.data.frame(x0)) {
    out <- apply(
      x0, 1, project_onto_variety_gradient_descent,
      poly = poly,
      varorder = varorder,
      ga = ga,
      max_ga = max_ga,
      method = method,
      tol = tol, tol_x = tol_x,
      maxit = maxit, message = message
    )
    out <- t(out)
    if (is.data.frame(x0)) out <- as.data.frame(out)
    if (inherits(x0, "tbl_df")) class(out) <- c("tbl_df", "tbl", "data.frame")
    return(out)
  }

  # Validate and dispatch descent strategy.
  method <- match.arg(method)

  # Build objective, gradient, and Hessian helpers for g(x)^2.
  pf  <- as.function(poly, varorder = varorder, silent = TRUE)
  p2f <- as.function(poly^2, varorder = varorder, silent = TRUE)
  dp2 <- stats::deriv(poly^2, var = varorder)
  dp2f <- as.function(dp2, varorder = varorder, silent = TRUE)
  ddp2 <- lapply(dp2, function(.) stats::deriv(., var = varorder))
  ddp2f <- function(v) {
    sapply(
      lapply(ddp2, as.function, silent = TRUE),
      function(f) f(v)
    )
  }


  if (method == "optimal") {

    xn_2 <- x0

    direction_2 <- dp2f(xn_2)
    ga <- stats::optimize(
      function(.) p2f(xn_2 - . * direction_2),
      lower = 0,
      upper = max_ga
    )$minimum
    xn_1 <- xn_2 - ga*direction_2
    if (message) message(paste(round(xn_1, 5), collapse = " "))

    direction_1 <- dp2f(xn_1)
    ga <- stats::optimize(
      function(.) p2f(xn_1 - . * direction_1),
      lower = 0,
      upper = max_ga
    )$minimum
    xn <- xn_1 - ga*direction_1
    if (message) message(paste(round(xn, 5), collapse = " "))

    count <- 0
    while (abs(p2f(xn)) > tol && sum(abs(xn-xn_1)) > tol_x && count <= maxit) {
      xn_2 <- xn_1
      xn_1 <- xn
      direction_2 <- dp2f(xn_2)
      direction_1 <- dp2f(xn_1)
      ga <- abs(
        sum((xn_1 - xn_2) * (direction_1 - direction_2))
      ) / sum((direction_1 - direction_2)^2)
      xn   <- xn_1 - ga*direction_1
      count <- count + 1
      if (message) message(paste(round(xn, 5), collapse = " "))
    }

  } else if (method == "line") {

    xn_1 <- x0

    direction <- dp2f(xn_1)
    ga <- stats::optimize(
      function(.) p2f(xn_1 - . * direction),
      lower = 0,
      upper = max_ga
    )$minimum
    xn <- xn_1 - ga*dp2f(xn_1)
    if (message) message(paste(round(xn, 5), collapse = " "))

    count <- 0
    while (abs(p2f(xn)) > tol && sum(abs(xn-xn_1)) > tol_x && count <= maxit) {
      xn_1 <- xn
      direction <- dp2f(xn_1)
      ga <- stats::optimize(
        function(.) p2f(xn_1 - . * direction),
        lower = 0,
        upper = max_ga
      )$minimum
      xn   <- xn_1 - ga*direction
      count <- count + 1
      if (message) message(paste(round(xn, 5), collapse = " "))
    }

  } else if (method == "fixed") {

    xn_1 <- x0

    direction <- dp2f(xn_1)
    xn <- xn_1 - ga*direction
    if (message) message(paste(round(xn, 5), collapse = " "))

    count <- 0
    while (abs(p2f(xn)) > tol && sum(abs(xn-xn_1)) > tol_x && count <= maxit) {
      xn_1 <- xn
      direction <- dp2f(xn_1)
      xn   <- xn_1 - ga*direction
      count <- count + 1
      if (message) message(paste(round(xn, 5), collapse = " "))
    }

  }

  resid <- pf(xn)
  if (abs(resid) >= tol) {
    warning(
      sprintf("Tolerance not met (residual = %f).", resid),
      call. = FALSE
    )
  }

  xn
}








#' @rdname project-onto-variety
#' @export
project_onto_variety_newton <- function(
    x0, poly, varorder = mpoly::vars(poly), ga = 1e-4, max_ga = 2,
    method = c("line", "fixed"),
    tol = .Machine$double.eps^(1/2), tol_x = .Machine$double.eps^(1/2),
    maxit = 1e3, message = FALSE
) {
  # Minimize g(x)^2 with Newton updates and optional line search.

  # Vectorized convenience path for row-wise projection.
  if (is.matrix(x0) || is.data.frame(x0)) {
    out <- apply(
      x0, 1, project_onto_variety_newton,
      poly = poly, varorder = varorder, ga = ga, max_ga = max_ga,
      method = method, tol = tol, tol_x = tol_x,
      maxit = maxit, message = message
    )
    out <- t(out)
    if (is.data.frame(x0)) out <- as.data.frame(out)
    if (inherits(x0, "tbl_df")) class(out) <- c("tbl_df", "tbl", "data.frame")
    return(out)
  }

  # Validate method option.
  method <- match.arg(method)

  # Build objective, gradient, and Hessian helpers for g(x)^2.
  pf  <- as.function(poly, varorder = varorder, silent = TRUE)
  p2f <- as.function(poly^2, varorder = varorder, silent = TRUE)
  dp2 <- stats::deriv(poly^2, var = varorder)
  dp2f <- as.function(dp2, varorder = varorder, silent = TRUE)
  ddp2 <- lapply(dp2, function(.) stats::deriv(., var = varorder))
  ddp2f <- function(v) {
    sapply(
      lapply(ddp2, as.function, silent = TRUE),
      function(f) f(v)
    )
  }

  # Iterative Newton updates.
  xn_1 <- x0

  direction <- solve(ddp2f(xn_1), -dp2f(xn_1))
  if (method == "line") {
    ga <- stats::optimize(
      function(.) p2f(xn_1 + . * direction),
      lower = 0,
      upper = max_ga
    )$minimum
  }
  xn <- xn_1 + ga*direction
  if (message) message(paste(round(xn, 5), collapse = " "))

  count <- 0
  while (abs(p2f(xn)) > tol && sum(abs(xn-xn_1)) > tol_x && count <= maxit) {
    xn_1 <- xn
    direction <- solve(ddp2f(xn_1), -dp2f(xn_1))
    if (method == "line") {
      ga <- stats::optimize(
        function(.) p2f(xn_1 + . * direction),
        lower = 0,
        upper = max_ga
      )$minimum
    }
    xn   <- xn_1 + ga*direction
    count <- count + 1
    if (message) message(paste(round(xn, 5), collapse = " "))
  }


  resid <- pf(xn)
  if (abs(resid) >= tol) {
    warning(
      sprintf("Tolerance not met (residual = %f).", resid),
      call. = FALSE
    )
  }

  xn
}

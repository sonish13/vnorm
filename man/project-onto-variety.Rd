% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/project_onto_variety.R
\name{project-onto-variety}
\alias{project-onto-variety}
\alias{project_onto_variety}
\alias{project_onto_variety_lagrange}
\alias{project_onto_variety_gradient_descent}
\alias{project_onto_variety_newton}
\title{Projection onto a variety}
\usage{
project_onto_variety(
  x0,
  poly,
  dt = 0.01,
  varorder = sort(mpoly::vars(poly)),
  n_correct = 2,
  al = rnorm(length(x0)),
  message = FALSE,
  tol = .Machine$double.eps^(1/2),
  gfunc,
  dgfunc,
  ddgfunc,
  bias = 0,
  adaptive = TRUE,
  dt_min = 1e-06,
  dt_max = 0.1,
  error_tol = 0.01
)

project_onto_variety_lagrange(
  x0,
  poly,
  varorder = mpoly::vars(poly),
  method = "newton",
  maxit = 1000,
  tol = .Machine$double.eps^(1/2),
  tol_x = .Machine$double.eps^(1/2),
  message = FALSE,
  ...
)

project_onto_variety_gradient_descent(
  x0,
  poly,
  varorder = mpoly::vars(poly),
  ga = 0.01,
  max_ga = 0.1,
  method = c("line", "optimal", "fixed"),
  tol = .Machine$double.eps^(1/2),
  tol_x = .Machine$double.eps^(1/2),
  maxit = 1000,
  message = FALSE
)

project_onto_variety_newton(
  x0,
  poly,
  varorder = mpoly::vars(poly),
  ga = 1e-04,
  max_ga = 2,
  method = c("line", "fixed"),
  tol = .Machine$double.eps^(1/2),
  tol_x = .Machine$double.eps^(1/2),
  maxit = 1000,
  message = FALSE
)
}
\arguments{
\item{x0}{Atomic vector, the point to be projected.}

\item{poly}{An mpoly object, typically created with \code{\link[mpoly:mp]{mpoly::mp()}}.}

\item{dt}{The t-mesh size for the homotopy.}

\item{varorder}{A character vector specifying the variable order to pass to
\code{\link[mpoly:as-function]{mpoly::as.function.mpoly()}}.}

\item{n_correct}{The number of Newton correction iterations to use.}

\item{al}{A numeric vector of length 2; the patch to do projective
calculations over.}

\item{message}{If \code{TRUE}, the user is issued messages on the algorithm's
progress.}

\item{tol}{A tolerance on the residual; a warning is issued if the magnitude
of the residual is larger than \code{tol}.}

\item{gfunc, dgfunc, ddgfunc}{The polynomial \link{poly}, its gradient, and its
Hessian as functions. Only used in \code{\link[=project_onto_variety]{project_onto_variety()}}, and computed
internally if not provided.}

\item{bias}{A multiple to add to the identity to make the Jacobian
invertible.}

\item{adaptive}{Defaults to \code{TRUE}. Whether to use adaptive stepsizes or not.}

\item{dt_min, dt_max}{Minimum and maximum allowed step sizes during adaptive
integration (default: \code{1e-6} and \code{0.1}).}

\item{error_tol}{Tolerance used for adaptive step size control
(default: \code{0.1}). Smaller values give more accurate results at the cost of runtime.}

\item{method}{Used in \code{\link[=project_onto_variety_lagrange]{project_onto_variety_lagrange()}} and
\code{\link[=project_onto_variety_gradient_descent]{project_onto_variety_gradient_descent()}}. In the former, if
\code{"newton"}, a simple R implementation of Newton's method to solve the
nonlinear algebraic system generated by the Lagrangian; otherwise, a
character string to pass to \code{\link[stats:optim]{stats::optim()}} to minimize the sum of the squares of
the Lagrangian. In the latter, the method of selecting the learning rate,
\code{"line"} (line search) or \code{"fixed"}.}

\item{maxit}{Number of maximum iterations in solving Newton's method.}

\item{tol_x}{A tolerance on subsequent step sizes.}

\item{...}{Additional arguments to pass to \code{\link[stats:optim]{stats::optim()}} when \code{method} is
not \code{"newton"}.}

\item{ga}{Learning rate for gradient descent.}

\item{max_ga}{Maximum learning rate for gradient descent line search.}

\item{t_start, t_end}{Start and end times for homotopy integration (default:
\code{1} to \code{0}).}
}
\value{
A numeric vector the same length as \code{x0}.
}
\description{
A R-based implementation of the gradient descent homotopies with adaptive
step sizes for Euler's prediction. The lagrange
version uses Newton's method on the Lagrangian system.
}
\examples{


library("ggplot2")


## basic usage
########################################

x0 <- c(1,1)
p <- mpoly::mp("x^2 + y^2 - 1")
(x0_proj <- project_onto_variety(x0, p))

as.function(p)(x0_proj)
sqrt(2)/2

cbind(t(x0), t(x0_proj)) |>
  as.data.frame() |> tibble::as_tibble() |>
  purrr::set_names(c("x", "y", "x_proj", "y_proj")) -> df

ggplot() +
  geom_variety(poly = p, xlim = c(-2, 2), ylim = c(-2, 2)) +
  geom_segment(
    aes(x, y, xend = x_proj, yend = y_proj),
    data = df) +
   theme(legend.position = "bottom")

# alternatives
1 / sqrt(2)
project_onto_variety_lagrange(x0, p)
project_onto_variety_newton(x0, p)
project_onto_variety_gradient_descent(x0, p)
project_onto_variety_gradient_descent(x0, p, method = "line")


# number of variables > 2
x0 <- c(1,1,1)
p <- mpoly::mp("x^2 + y^2 + z^2 - 1")
1 / sqrt(3)
project_onto_variety(x0, p)
project_onto_variety_lagrange(x0, p)
project_onto_variety_newton(x0, p)
project_onto_variety_gradient_descent(x0, p)
project_onto_variety_gradient_descent(x0, p, method = "line")


## options
########################################

x0 <- c(1,1)
p <- mpoly::mp("x^2 + y^2 - 1")
project_onto_variety(x0, p, message = TRUE)
project_onto_variety(x0, p, dt = .25, message = TRUE)


# precomputing the function, gradient, and hessian
varorder <- c("x", "y")
gfunc <- as.function(p, varorder = varorder)

dg <- stats::deriv(p, var = varorder)
dgfunc <- as.function(dg, varorder = varorder)

ddg <- lapply(dg, stats::deriv, var = varorder)
ddgfunc_list <- lapply(ddg, as.function, varorder = varorder, silent = TRUE)
ddgfunc <- function(x) sapply(ddgfunc_list, function(f) f(x))

project_onto_variety(x0, p, gfunc = gfunc, dgfunc = dgfunc, ddgfunc = ddgfunc)

## adaptive time stepping examples
########################################

x0 <- c(1, 1)
p <- mpoly::mp("x^2 + y^2 - 1")

# Using adaptive time stepping (default)
x0_proj_adaptive <- project_onto_variety(x0, p, message = TRUE)

# For comparison, fixed step size (no adaptation)
x0_proj_fixed <- project_onto_variety(x0, p, adaptive = FALSE, dt = 0.01, message = TRUE)

# Using stricter error tolerance for adaptive stepping
x0_proj_strict <- project_onto_variety(x0, p, error_tol = 0.01, message = TRUE)

# Visualize
df_adaptive <- cbind(t(x0), t(x0_proj_adaptive)) |>
  as.data.frame() |> tibble::as_tibble() |>
  purrr::set_names(c("x", "y", "x_proj", "y_proj"))

ggplot() +
  geom_variety(poly = p, xlim = c(-2, 2), ylim = c(-2, 2)) +
  geom_segment(aes(x, y, xend = x_proj, yend = y_proj), data = df_adaptive) +
  coord_equal() +
  theme(legend.position = "bottom")


## changing adaptive control parameters
########################################

x0_proj_custom_adaptive <- project_onto_variety(
  x0, p,
  adaptive = TRUE,
  dt = 0.05,
  dt_min = 1e-5,
  dt_max = 0.2,
  error_tol = 0.05,
  message = TRUE
)


## larger systems
########################################

x0 <- c(1,1,1)
p <- mpoly::mp("x^2 + y^2 + z^2 - 1")
project_onto_variety(x0, p) # adaptive by default
project_onto_variety(x0, p, adaptive = FALSE, dt = 0.01) # fixed step size

## more complex example
########################################

p <- mpoly::mp("(x^2 + y^2)^2 - 2 (x^2 - y^2)")
ggplot() + geom_variety(poly = p) + coord_equal() +
theme(legend.position = "bottom")
(x0_proj <- project_onto_variety(x0, p))

cbind(t(x0), t(x0_proj)) |>
  as.data.frame() |> tibble::as_tibble() |>
  purrr::set_names(c("x", "y", "x_proj", "y_proj")) -> df
p <- mpoly::mp("(x^2 + y^2)^2 - 2 (x^2 - y^2)")
ggplot() +
  geom_variety(poly = p, xlim = c(-2, 2), ylim = c(-2, 2)) +
  coord_equal() +
  geom_segment(
    aes(x, y, xend = x_proj, yend = y_proj),
    data = df, inherit.aes = FALSE
  ) +
   theme(legend.position = "bottom")



## projecting a dataset - grid
########################################

library("ggplot2")
library("dplyr")

(p <- mpoly::lissajous(5, 5, 0, 0))
# (p <- mpoly::lissajous(9, 9, 0, 0))
# p <- mpoly::mp("x^2 + y^2 - 1")
ggplot() +
  geom_variety(poly = p, n = 251) +
 coord_equal() +
   theme(legend.position = "bottom")
set.seed(1)
(s <- seq(-1, 1, .25))
n <- length(s)
grid <- expand.grid(x = s, y = s)
grid$x <- jitter(grid$x)
grid$y <- jitter(grid$y)

ggplot(grid, aes(x, y)) + geom_point() + coord_equal()

grid_proj <- project_onto_variety(grid, p)
head(grid_proj)
names(grid_proj) <- c("x_proj", "y_proj")

ggplot() +
  geom_variety(poly = p, n = 501, xlim = c(-2, 2), ylim = c(-2, 2)) +
  coord_equal() +
  geom_segment(
    aes(x, y, xend = x_proj, yend = y_proj),
    data = bind_cols(grid, grid_proj), inherit.aes = FALSE
  ) +
  geom_point(aes(x, y), data = grid, inherit.aes = FALSE) +
   theme(legend.position = "bottom")


# here's what happens when you use a naive implementation -
# gradient descent on g^2 with line search
grid_proj_gd <- project_onto_variety_gradient_descent(grid, p, method = "optimal")
names(grid_proj_gd) <- c("x_proj", "y_proj")

grid_proj_lagrange <- project_onto_variety_lagrange(grid, p)
names(grid_proj_lagrange) <- c("x_proj", "y_proj")

grid_proj_newton <- project_onto_variety_newton(grid, p)
names(grid_proj_newton) <- c("x_proj", "y_proj")

df <- bind_rows(
  bind_cols(grid, grid_proj) |> mutate(method = "gradient descent homotopy"),
  bind_cols(grid, grid_proj_gd) |> mutate(method = "optimal gradient descent"),
  bind_cols(grid, grid_proj_newton) |> mutate(method = "newton"),
  bind_cols(grid, grid_proj_lagrange) |> mutate(method = "newton on lagrangian")
)


ggplot() +
  geom_variety(poly = p, n = 501, xlim = c(-2, 2), ylim = c(-2, 2)) +
  geom_segment(
    aes(x, y, xend = x_proj, yend = y_proj),
    data = df, inherit.aes = FALSE
  ) +
  geom_point(aes(x, y), data = grid, inherit.aes = FALSE) +
  coord_equal() +
  facet_wrap(~ method) + xlim(-1.1, 1.1) + ylim(-1.1, 1.1) +
   theme(legend.position = "bottom")

## projecting a dataset - rvnorm
########################################

library("ggplot2")
library("dplyr")


(p <- mpoly::lissajous(5, 5, 0, 0))
ggplot() +
  geom_variety(poly = p, n = 501, xlim = c(-2, 2), ylim = c(-2, 2)) +
  coord_equal() +
   theme(legend.position = "bottom")
set.seed(1)
(samps <- rvnorm(1e4, p, sd = .025, output = "tibble"))

ggplot(samps, aes(x, y)) +
  geom_point(aes(color = .chain)) +
  coord_equal() +
  facet_wrap(~ .chain)

ggplot(samps, aes(x, y)) +
  geom_bin2d(binwidth = .03*c(1,1)) +
  coord_equal()

# cut down on draws for time
subsamps <- samps |> sample_n(500)
ggplot(subsamps, aes(x, y)) + geom_point() + coord_equal()

subsamps |>
  select(x, y) |>
  as.matrix() |>
  apply(1, function(x0) project_onto_variety_lagrange(x0, p)) |> t() |>
  as.data.frame() |> tibble::as_tibble() |>
  purrr::set_names(c("x_proj", "y_proj")) |>
  (\(df_proj) bind_cols(subsamps, df_proj))() ->
subsamps
 ggplot() +
  geom_variety(poly = p, n = 501, xlim = c(-2, 2), ylim = c(-2, 2)) +
  coord_equal() +
   theme(legend.position = "bottom") +
  geom_segment(
    aes(x, y, xend = x_proj, yend = y_proj),
    data = subsamps, inherit.aes = FALSE
  ) +
  geom_point(
    aes(x, y, color = factor(.chain)),
    data = subsamps, inherit.aes = FALSE
  )

ggplot(subsamps, aes(x_proj, y_proj)) + geom_point() + coord_equal()



}
\references{
Griffin, Z. and J. Hauenstein (2015). Real solutions to systems
of polynomial equations and parameter continuation. \emph{Advances in
Geometry} 15(2), pp.173--187.

Bates, D., J. Hauenstein, A. Sommese, and C. Wampler (2013).
Numerically Solving Polynomial Systems with Bertini. SIAM. pp.34--35.
}
\author{
David Kahle
}
